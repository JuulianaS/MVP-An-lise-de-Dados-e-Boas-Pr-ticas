# -*- coding: utf-8 -*-
"""MVP AnÃ¡lise de Dados e Boas PrÃ¡ticas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QyWgRWg2Q7r76WkHXsczTTnNWMXKGG4g

# MVP AnÃ¡lise de Dados e Boas PrÃ¡ticas
## AnÃ¡lise da Demanda de Medicamentos para CÃ¢ncer de PrÃ³stata (EstÃ¡gio AvanÃ§ado)

**Nome:** Juliana Silva

**MatrÃ­cula:** 4052025000237

**Dataset:** Demanda_Medicamentos.csv

**Contexto**

O cÃ¢ncer de prÃ³stata representa uma das principais causas de mortalidade masculina no Brasil, especialmente em estÃ¡gios avanÃ§ados ou metastÃ¡ticos da doenÃ§a. Nessa etapa, o tratamento farmacolÃ³gico Ã© essencial e envolve medicamentos altamente especializados, cujo consumo e valor movimentado podem refletir aspectos cruciais relacionados ao acesso Ã  saÃºde, gestÃ£o hospitalar, disponibilidade regional e estratÃ©gias comerciais das empresas farmacÃªuticas.

Este projeto utiliza dados reais fornecidos pela empresa IQVIA, lÃ­der global em informaÃ§Ãµes relacionadas Ã  saÃºde, onde atuo profissionalmente. Os dados foram devidamente anonimizados, garantindo total confidencialidade e conformidade com as normas Ã©ticas de privacidade e seguranÃ§a da informaÃ§Ã£o.

---

**Objetivo**

O objetivo deste projeto Ã© realizar uma anÃ¡lise exploratÃ³ria profunda sobre uma base de dados real, focando em medicamentos especÃ­ficos para o tratamento do cÃ¢ncer de prÃ³stata em estÃ¡gio avanÃ§ado. O estudo tem duas vertentes complementares:

* Modelo Preditivo de RegressÃ£o: Construir e validar um modelo preditivo capaz de estimar o valor monetÃ¡rio das vendas com base em atributos importantes como localizaÃ§Ã£o geogrÃ¡fica (estado, regiÃ£o), caracterÃ­sticas do produto (marca, concentraÃ§Ã£o), canal de venda (hospitalar, farmÃ¡cia ou outros) e quantidade comercializada;

* Modelo de PrevisÃ£o de SÃ©ries Temporais: Desenvolver uma previsÃ£o mensal das vendas totais (em valor e unidades) para os prÃ³ximos meses, utilizando o modelo Prophet, identificando tendÃªncias e auxiliando no planejamento estratÃ©gico futuro.

---

**Tipo de problema**

Trata-se de um problema de aprendizado supervisionado envolvendo duas abordagens:

* RegressÃ£o: para estimar o valor da venda individual com base em atributos explicativos.

* PrevisÃ£o Temporal: para estimar a demanda mensal total (valor e unidades) em perÃ­odos futuros.

---

**Premissas**

* A base de dados fornecida representa um conjunto confiÃ¡vel e representativo das vendas nacionais de medicamentos oncolÃ³gicos especÃ­ficos.

* O valor monetÃ¡rio das vendas ("VALOR") Ã© influenciado significativamente por fatores como canal de distribuiÃ§Ã£o, localizaÃ§Ã£o geogrÃ¡fica (cidade e regiÃ£o), tipo de medicamento e caracterÃ­sticas especÃ­ficas do produto (marca, concentraÃ§Ã£o, quantidade).

* A demanda mensal segue padrÃµes histÃ³ricos que podem ser capturados por modelos temporais, possibilitando previsÃµes eficazes.

---

**RestriÃ§Ãµes**

* UtilizaÃ§Ã£o exclusiva de dados nÃ£o sigilosos e completamente anonimizados, respeitando todas as normas de privacidade.

* Trabalhar com uma base de dados limpa, que nÃ£o tenha sofrido tratamentos prÃ©vios significativos ou transformaÃ§Ãµes que alterem as caracterÃ­sticas originais dos dados.

Essa abordagem dupla permite uma compreensÃ£o robusta e estratÃ©gica do mercado desses medicamentos, ajudando a embasar decisÃµes relacionadas Ã  gestÃ£o pÃºblica e privada da saÃºde, estratÃ©gias comerciais, logÃ­sticas e polÃ­ticas de acesso aos tratamentos.

### 2. Carregamento e VisualizaÃ§Ã£o Inicial dos Dados
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import cross_val_score, KFold
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_regression
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error
import plotly.express as px
from IPython.display import display

# ConfiguraÃ§Ãµes de exibiÃ§Ã£o
pd.set_option('display.float_format', lambda x: '%.2f' % x)
sns.set(style="whitegrid")

# Carregamento dos dados (leitura com separador ;)
url = ("https://raw.githubusercontent.com/JuulianaS/MVP-An-lise-de-Dados-e-Boas-Pr-ticas/refs/heads/main/Demanda_Medicamentos.csv")
df = pd.read_csv(url, sep=';')

# Visualizar as primeiras linhas do dataset
df.head()

"""AnÃ¡lise inicial:
O dataset possui mÃºltiplas variÃ¡veis categÃ³ricas e numÃ©ricas, essenciais para uma anÃ¡lise detalhada do comportamento de vendas

### 3. DicionÃ¡rio de Atributos

* **DT_PERIODO:** Ano e mÃªs da venda
* **SG_UF:** Sigla da unidade federativa (estado)
* **DC_CIDADE:** Nome da cidade
* **PRODUTO:** Nome do produto
* **CONCENTRACAO:** Dosagem do produto
* **QDTE_PRODUTO:** Quantidade do produto
* **MARCA:** Nome da marca
* **CANAL:** Canal de venda (farmÃ¡cia, hospital, outros)
* **CLASSE_TERAPEUTICA**: Classe do medicamento
* **INDICAÃ‡ÃƒO:** IndicaÃ§Ã£o terapÃªutica
* **FORMA_FARMACEUTICA:** Forma (ex: comprimido)
* **DC_NACIONAL_MULTINACIONAL:** Origem da empresa
* **DC_GRMS:** Categoria regulatÃ³ria (genÃ©rico etc.)
* **DC_ETICO_POPULAR:** Tipo de medicamento
* **DC_CONCENTRACAO:** Unidade de concentraÃ§Ã£o (ex: mg)
* **PACK_DCT_DISEASE_DESC:** DoenÃ§a associada (ex: CÃ¢ncer)
* **PACK_IS_RX_IND:** Medicamento prescrito ou nÃ£o
* **UNIDADES:** Quantidade de unidades vendidas
* **VALOR:** Valor monetÃ¡rio da venda


---


A base combina atributos temporais, geogrÃ¡ficos, comerciais e clÃ­nicos, o que permite uma anÃ¡lise rica.

Os atributos numÃ©ricos (VALOR, UNIDADES, QDTE_PRODUTO) sÃ£o chave para a modelagem.

Os categÃ³ricos como CANAL, MARCA, PRODUTO e SG_UF sÃ£o importantes para segmentaÃ§Ãµes e explicaÃ§Ãµes do valor.

Atributos como INDICAÃ‡ÃƒO e CLASSE_TERAPEUTICA sÃ£o Ãºteis para confirmar o escopo clÃ­nico, embora menos usados em modelagem.

### 4. InformaÃ§Ãµes BÃ¡sicas e Tipos de Dados
"""

# Verificar o formato do dataset
print("Formato do dataset:", df.shape)

"""
*   Ajuda a ter uma noÃ§Ã£o do volume de dados disponÃ­veis para anÃ¡lise.
*   Fundamental para saber se o dataset tem ampla cobertura ou se Ã© necessÃ¡rio reduzir ou amostrar dados."""

# Mostra os tipos de dados
print("\nTipos de dados:")
print(df.dtypes)

"""**O que faz:**
Exibe o tipo de dado de cada coluna do DataFrame (ex: object, int64, float64).

**Por que isso Ã© importante:**


*   Determina como cada variÃ¡vel serÃ¡ tratada na anÃ¡lise e modelagem.

    1.   object = categÃ³rico ou texto (precisa de codificaÃ§Ã£o).
    2.   int64 ou float64 = numÃ©rico (pode ser escalado, padronizado, etc.).


*   Identifica se hÃ¡ necessidade de conversÃµes (por exemplo: datas, nÃºmeros lidos como texto).
*   Impacta diretamente no prÃ©-processamento.
"""

# Verificar valores Ãºnicos por coluna
print("\nValores Ãºnicos por coluna:")
print(df.nunique())

"""**O que faz:**
Mostra quantos valores distintos (Ãºnicos) existem em cada coluna.

**Por que isso Ã© importante:**


*   Ajuda a entender a variabilidade dos dados:

    1.   VariÃ¡veis com apenas 1 valor = inÃºteis (sem informaÃ§Ã£o).
    2.   VariÃ¡veis com muitos valores Ãºnicos (ex: DC_CIDADE) = podem gerar alta cardinalidade â†’ cuidado em codificaÃ§Ã£o.


*   Ajuda na detecÃ§Ã£o de erros, por exemplo: colunas que deveriam ter poucos valores mas tÃªm muitos (sinal de ruÃ­do ou erro de entrada).

### 5. EstatÃ­sticas Descritivas
"""

# Resumo estatÃ­stico dos atributos numÃ©ricos
print(df[['QDTE_PRODUTO', 'UNIDADES', 'VALOR']].describe())

"""**O que isso indica:**

QDTE_PRODUTO

  *   A maior parte dos registros apresenta valor fixo de 120.
  *   Quase nenhum desvio ou variaÃ§Ã£o.

UNIDADES

  *   Varia de 1 a 1.375 unidades por venda, com mÃ©dia de ~6 unidades.
  *   O desvio padrÃ£o (19,56) Ã© muito maior que a mÃ©dia (5,92) â†’ isso indica alta dispersÃ£o.
  *   HÃ¡ outliers evidentes em unidades vendidas.

VALOR

  *   Valores variam de 8 mil a mais de 12 milhÃµes por venda.
  *   MÃ©dia distorcida por outliers extremos.
  *   A mediana (R$ 26.708) Ã© muito menor que a mÃ©dia â†’ assimetria positiva forte. (Ã‰ necessÃ¡rio tratar outliers e talvez normalizar essa variÃ¡vel.)





"""

# Verificar valores ausentes
print("\nValores ausentes:")
print(df.isnull().sum())

"""Verifica se hÃ¡ valores ausentes (nulos) em cada coluna do dataset.

**O que isso indica:**

*   NÃ£o Ã© necessÃ¡rio aplicar preenchimento ou remoÃ§Ã£o de dados faltantes.
*   Facilita a aplicaÃ§Ã£o de algoritmos de machine learning, que exigem dados completos.
*   Isso Ã© um bom sinal da qualidade dos dados fornecidos pela IQVIA, mostrando consistÃªncia.

### 6. VisualizaÃ§Ãµes Iniciais
"""

df['REGIAO'] = df['SG_UF'].map(lambda uf: (
    'Norte' if uf in ['AM', 'PA', 'TO', 'RO', 'RR', 'AC', 'AP'] else
    'Nordeste' if uf in ['MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA'] else
    'Centro-Oeste' if uf in ['MT', 'MS', 'GO', 'DF'] else
    'Sudeste' if uf in ['SP', 'RJ', 'MG', 'ES'] else
    'Sul'
))

plt.figure(figsize=(10,6))
sns.countplot(y='REGIAO', data=df, order=df['REGIAO'].value_counts().index)
plt.title('DistribuiÃ§Ã£o das Vendas por RegiÃ£o')
plt.xlabel('NÃºmero de Vendas')
plt.ylabel('RegiÃ£o')
plt.show()

"""**AnÃ¡lise:**

Podemos verificar se existe concentraÃ§Ã£o de vendas em regiÃµes especÃ­ficas, o que ajudarÃ¡ na interpretaÃ§Ã£o regional do mercado.
"""

# DistribuiÃ§Ã£o do valor de vendas
plt.figure(figsize=(10, 5))
sns.histplot(df['VALOR'], bins=50, kde=True)
plt.title('DistribuiÃ§Ã£o do Valor das Vendas')
plt.xlabel('Valor (R$)')
plt.ylabel('FrequÃªncia')
plt.show()

"""**ObservaÃ§Ã£o:**


*   HÃ¡ uma forte assimetria Ã  direita, indicando presenÃ§a de valores elevados que podem ser considerados outliers.
*   PresenÃ§a de outliers com valores milionÃ¡rios, que devem ser tratados.


"""

# DistribuiÃ§Ã£o por canal
plt.figure(figsize=(8, 4))
sns.countplot(data=df, x='CANAL')
plt.title('DistribuiÃ§Ã£o por Canal de Venda')
plt.xlabel('Canal')
plt.ylabel('Contagem')
plt.show()

"""**ObservaÃ§Ã£o:**

Canais hospitalares tendem a ter maior volume nesse tipo de medicamento especializado, mas a distribuiÃ§Ã£o pode variar por regiÃ£o ou tipo de produto.
"""

# CriaÃ§Ã£o da Matriz de DispersÃ£o
sns.pairplot(df[['QDTE_PRODUTO', 'UNIDADES', 'VALOR']])
plt.show()

"""**ObservaÃ§Ã£o:**

A matriz de dispersÃ£o ajuda a identificar relaÃ§Ãµes lineares entre variÃ¡veis numÃ©ricas. Observamos relaÃ§Ã£o positiva entre quantidade e valor.

*   QDTE_PRODUTO: A enorme maioria dos registros tem valor exatamente 120, com rarÃ­ssimas exceÃ§Ãµes (outros valores prÃ³ximos de 60).
*   UNIDADES Ã— VALOR: Claramente hÃ¡ uma relaÃ§Ã£o positiva forte (quanto mais unidades vendidas, maior o valor total).
*   QDTE_PRODUTO Ã— UNIDADES: Todos os pontos com (QDTE_PRODUTO = 120), e dispersÃ£o em UNIDADES.
*   QDTE_PRODUTO Ã— VALOR: Os valores de VALOR se espalham mesmo quando (QDTE_PRODUTO = 120), o que mostra falta de correlaÃ§Ã£o direta.
*   VALOR Ã— UNIDADES: Visualmente quase uma linha crescente, confirmando a forte correlaÃ§Ã£o positiva. TambÃ©m Ã© possÃ­vel perceber a presenÃ§a de outliers, com vendas de valores muito altos (acima de R$ 10 milhÃµes).

### 7. AnÃ¡lise de Outliers
"""

# Boxplot para a anÃ¡lise
plt.figure(figsize=(10, 5))
sns.boxplot(x=df['VALOR'])
plt.title('Boxplot do Valor das Vendas')
plt.show()

"""**Motivo da anÃ¡lise:**

Identificar visualmente valores extremos para melhor tratÃ¡-los no prÃ©-processamento.

*   A variÃ¡vel VALOR tem muitos outliers positivos (vendas de altÃ­ssimo valor).
*   Existe alta variabilidade no valor das vendas.
*   A distribuiÃ§Ã£o nÃ£o Ã© normal: Ã© altamente assimÃ©trica, o que afeta algoritmos sensÃ­veis Ã  distribuiÃ§Ã£o (como regressÃ£o linear).

#### CorreÃ§Ã£o dos outliers
"""

# RemoÃ§Ã£o de outliers com base no IQR
Q1 = df['VALOR'].quantile(0.25)
Q3 = df['VALOR'].quantile(0.75)
IQR = Q3 - Q1
filtro = (df['VALOR'] >= Q1 - 1.5 * IQR) & (df['VALOR'] <= Q3 + 1.5 * IQR)
df_limpo = df[filtro].copy()

"""Motivo do tratamento: A remoÃ§Ã£o dos outliers melhora a precisÃ£o dos modelos preditivos, eliminando valores extremos."""

# Verifica os dados atualizados
sns.boxplot(x=df_limpo['VALOR'])

"""**O que vemos:**

*   A distribuiÃ§Ã£o estÃ¡ muito mais concentrada e simÃ©trica.
*   A faixa principal de valores estÃ¡ entre cerca de R$ 14 mil e R$ 80 mil.
*   Existem alguns outliers ainda presentes, mas em quantidade pequena â€” o que Ã© esperado e aceitÃ¡vel.

**ConclusÃ£o:**

*   A tÃ©cnica de remoÃ§Ã£o de outliers via IQR foi eficaz.
*   Agora temos uma base muito mais estÃ¡vel para modelagem preditiva.
*   Os dados ficaram mais adequados para algoritmos que assumem simetria ou baixa variÃ¢ncia.

"""

df_limpo['VALOR_LOG'] = np.log1p(df_limpo['VALOR'])  # log1p trata log(0)

plt.figure(figsize=(10, 5))
sns.histplot(df_limpo['VALOR_LOG'], bins=50, kde=True)
plt.title('DistribuiÃ§Ã£o do Log do Valor das Vendas')
plt.xlabel('log(VALOR + 1)')
plt.ylabel('FrequÃªncia')
plt.show()

"""**O que vemos:**

*   A transformaÃ§Ã£o logarÃ­tmica suavizou a assimetria.
*   A nova distribuiÃ§Ã£o apresenta picos (modas) em vÃ¡rios pontos â†’ indica que existem grupos distintos de preÃ§os/vendas, possivelmente:

      1.   Por tipo de produto.
      2.   Por canal (hospitalar x farmÃ¡cia).
      3.   Por regiÃ£o ou marca.

**ConclusÃ£o:**
*   A distribuiÃ§Ã£o de log(VALOR) estÃ¡ mais prÃ³xima de uma distribuiÃ§Ã£o normal, o que Ã© ideal para regressÃ£o linear e muitos outros modelos estatÃ­sticos.
*   Com isso, pode-se optar por treinar o modelo usando log(VALOR) como variÃ¡vel-alvo, e aplicar exp() depois para reverter a previsÃ£o.



"""

# Resumo estatÃ­stico agora com os dados limpos
print(df_limpo[['QDTE_PRODUTO', 'UNIDADES', 'VALOR']].describe())

"""**InterpretaÃ§Ã£o e ComparaÃ§Ã£o**

**QDTE_PRODUTO**

*   Permanece praticamente inalterada: a variÃ¡vel jÃ¡ apresentava valores muito concentrados em 120, com pouca variabilidade.
*   A limpeza de outliers nÃ£o impactou essa variÃ¡vel.


**UNIDADES**
DistribuiÃ§Ã£o equilibrada apÃ³s remoÃ§Ã£o de outliers:

*   MÃ©dia caiu de 5,92 para 2,98, e o mÃ¡ximo de 1.375 foi reduzido para 54.
*   O desvio padrÃ£o tambÃ©m caiu drasticamente (de 19,56 â†’ 3,00).
*   Isso mostra que a variÃ¡vel tinha muitos outliers extremos, que estavam distorcendo a mÃ©dia e inflando a variabilidade.

Essa variÃ¡vel agora estÃ¡ muito mais estÃ¡vel e confiÃ¡vel para uso como preditora.

**VALOR**
*   A mÃ©dia do valor caiu mais de 50% (R$ 63 mil â†’ R$ 29 mil), e o desvio padrÃ£o caiu mais de 85%.
*   O mÃ¡ximo foi reduzido de R$ 12,5 milhÃµes para R$ 114 mil, removendo claramente vendas fora do padrÃ£o.
*   A mediana caiu de R$ 26 mil para R$ 16 mil, mostrando que parte dos valores intermediÃ¡rios tambÃ©m foram suavizados.
*   Agora a variÃ¡vel estÃ¡ menos assimÃ©trica e mais adequada para modelagem (principalmente para modelos lineares).

#### ConclusÃ£o

A remoÃ§Ã£o de outliers foi fundamental para reduzir distÃºrbios estatÃ­sticos nas variÃ¡veis UNIDADES e VALOR.

O impacto na mÃ©dia, desvio padrÃ£o e valor mÃ¡ximo mostra que os dados estavam altamente influenciados por poucos registros extremos, especialmente em vendas de alto volume e valor.

Com os dados limpos, a base estÃ¡:

1.   Mais equilibrada e estÃ¡vel;
2.   Mais compatÃ­vel com tÃ©cnicas de regressÃ£o;
3.   Menos propensa a overfitting em valores extremos.

Essa limpeza representa uma etapa crucial de prÃ©-processamento para garantir robustez, interpretabilidade e performance na modelagem preditiva.

---

**AvaliaÃ§Ã£o do impacto da remoÃ§Ã£o de Outliers**

ApÃ³s a remoÃ§Ã£o dos outliers utilizando o mÃ©todo IQR, observamos melhorias significativas na estabilidade dos dados:

Antes da remoÃ§Ã£o, a mÃ©dia do valor monetÃ¡rio (VALOR) era R$ 63.725, com desvio padrÃ£o de R$ 195.498 e valores extremos superiores a R$ 12 milhÃµes.

Depois da remoÃ§Ã£o, a mÃ©dia caiu para R$ 29.327, o desvio padrÃ£o diminuiu drasticamente para R$ 23.385 e o mÃ¡ximo foi reduzido para R$ 114 mil.

Essa limpeza nÃ£o apenas reduziu a variabilidade exagerada, como tambÃ©m tornou os dados mais compatÃ­veis com modelos estatÃ­sticos, especialmente aqueles sensÃ­veis a outliers, como a RegressÃ£o Linear. Para verificar precisamente o impacto no desempenho dos modelos, Ã© recomendado comparar rapidamente a performance dos modelos antes e apÃ³s essa etapa.

### 8. Feature Engineering
"""

# CriaÃ§Ã£o de valor unitÃ¡rio (valor por unidade vendida)
df_limpo['VALOR_UNITARIO'] = df_limpo['VALOR'] / df_limpo['UNIDADES']

"""**O que faz:**

Calcula o valor por unidade vendida, ou seja, o preÃ§o mÃ©dio por unidade de medicamento.

**Por que Ã© importante:**

*   Normaliza o valor total pela quantidade.
*   Permite comparar preÃ§os entre produtos e canais, independentemente do volume vendido.
*   Reduz viÃ©s causado por vendas com grandes quantidades.


**Impacto analÃ­tico:**

Torna possÃ­vel avaliar estratÃ©gias comerciais (ex: posicionamento de preÃ§o por regiÃ£o ou canal).


"""

# DistribuiÃ§Ã£o do valor unitÃ¡rio
plt.figure(figsize=(10, 5))
sns.histplot(df_limpo['VALOR_UNITARIO'], bins=50, kde=True)
plt.title('DistribuiÃ§Ã£o do Valor UnitÃ¡rio (VALOR / UNIDADES)')
plt.xlabel('Valor UnitÃ¡rio (R$)')
plt.ylabel('FrequÃªncia')
plt.show()

# ExtraÃ§Ã£o de mÃªs e ano do campo DT_PERIODO
df_limpo['ANO'] = df_limpo['DT_PERIODO'] // 100
df_limpo['MES'] = df_limpo['DT_PERIODO'] % 100

"""**O que faz:**

DecompÃµe a data no formato AAAAMM em dois atributos distintos: ano e mÃªs.

**Por que Ã© importante:**


*   Permite anÃ¡lises temporais (tendÃªncia, sazonalidade, ciclos de compra).
*   Essencial para sÃ©ries temporais, agrupamentos por mÃªs ou trimestre, e atÃ© para prever demanda futura.


**Impacto analÃ­tico:**

Com essas colunas, pode observar flutuaÃ§Ãµes de demanda ao longo do tempo, associar polÃ­ticas pÃºblicas a perÃ­odos especÃ­ficos ou prever vendas futuras.
"""

plt.figure(figsize=(8, 4))
sns.countplot(x='ANO', data=df_limpo)
plt.title('DistribuiÃ§Ã£o de Registros por Ano')
plt.xlabel('Ano')
plt.ylabel('Contagem')
plt.show()

# Agrupamento de regiÃµes
regioes = {
    'Norte': ['AM', 'PA', 'TO', 'RO', 'RR', 'AC', 'AP'],
    'Nordeste': ['MA', 'PI', 'CE', 'RN', 'PB', 'PE', 'AL', 'SE', 'BA'],
    'Centro-Oeste': ['MT', 'MS', 'GO', 'DF'],
    'Sudeste': ['SP', 'RJ', 'MG', 'ES'],
    'Sul': ['PR', 'RS', 'SC']
}
def map_regiao(uf):
    for regiao, estados in regioes.items():
        if uf in estados:
            return regiao
    return 'Desconhecida'

df_limpo['REGIAO'] = df_limpo['SG_UF'].apply(map_regiao)

"""**O que faz:**

Agrupa os estados brasileiros (SG_UF) em suas respectivas regiÃµes geogrÃ¡ficas oficiais.

**Por que Ã© importante:**


*   Reduz o nÃºmero de categorias (de 27 estados para 5 regiÃµes).
*   Facilita anÃ¡lises geogrÃ¡ficas agregadas, sem perder granularidade.
*   Pode revelar diferenÃ§as estruturais no comportamento de compra entre regiÃµes.

**Impacto analÃ­tico:**

Permite segmentar estratÃ©gias por regiÃ£o, estudar desigualdades no acesso ao tratamento e observar padrÃµes de mercado regionais.
"""

# DistribuiÃ§Ã£o por regiÃ£o
plt.figure(figsize=(8, 4))
sns.countplot(y='REGIAO', data=df_limpo, order=df_limpo['REGIAO'].value_counts().index)
plt.title('DistribuiÃ§Ã£o de Vendas por RegiÃ£o')
plt.xlabel('NÃºmero de Registros')
plt.ylabel('RegiÃ£o')
plt.show()

"""### 9. SeleÃ§Ã£o de CaracterÃ­sticas com SelectKBest

**Objetivo:**

Reduzir a dimensionalidade do conjunto de dados, mantendo apenas os atributos mais relevantes para previsÃ£o do valor (VALOR) da venda.
"""

# SeleÃ§Ã£o inicial de atributos
features = ['SG_UF', 'CANAL', 'MARCA', 'PRODUTO', 'FORMA_FARMACEUTICA', 'REGIAO']
numeric = ['QDTE_PRODUTO', 'UNIDADES', 'VALOR_UNITARIO', 'MES', 'ANO']
target = 'VALOR'

X_full = df_limpo[features + numeric]
y_full = df_limpo[target]

"""**ExplicaÃ§Ã£o:**

X_full contÃ©m as variÃ¡veis independentes: categÃ³ricas + numÃ©ricas.

y_full Ã© a variÃ¡vel dependente (valor monetÃ¡rio da venda).

#### PadronizaÃ§Ã£o
"""

# Pipeline com prÃ©-processador e seletor
preprocessador = ColumnTransformer([
    ("onehot", OneHotEncoder(handle_unknown='ignore'), features),
    ("escala", StandardScaler(), numeric)
])

"""**O que faz:**

*   Converte variÃ¡veis categÃ³ricas em vetores binÃ¡rios com OneHotEncoder.
*   Escala variÃ¡veis numÃ©ricas com StandardScaler (mÃ©dia 0, desvio-padrÃ£o 1).

**Justificativa:**

*   Modelos como regressÃ£o linear e tÃ©cnicas baseadas em distÃ¢ncia exigem dados em escala comum.
*   OneHotEncoder Ã© ideal para tratar variÃ¡veis categÃ³ricas com muitas categorias (como PRODUTO, CANAL, etc.).








"""

X_trans = preprocessador.fit_transform(X_full)

"""**O que faz:**

Aplica o prÃ©-processador para gerar uma matriz totalmente numÃ©rica e escalada, pronta para ser usada no modelo ou no seletor.


"""

# AplicaÃ§Ã£o do SelectKBest para pegar as 20 features mais relevantes
selector = SelectKBest(score_func=f_regression, k=20)
X_selected = selector.fit_transform(X_trans, y_full)

"""**O que faz:**

Usa testes estatÃ­sticos (neste caso, ANOVA F-test para regressÃ£o) para selecionar as 20 variÃ¡veis mais relevantes que possuem maior correlaÃ§Ã£o com o alvo VALOR.

**Justificativa:**

Reduz ruÃ­do e dimensionalidade, o que:

1.   Aumenta a eficiÃªncia computacional;
2.   Melhora a performance do modelo;
3.   Evita o problema da maldiÃ§Ã£o da dimensionalidade.
"""

# Recuperar os nomes das features apÃ³s transformaÃ§Ã£o
onehot_features = preprocessador.named_transformers_['onehot'].get_feature_names_out(features)
all_feature_names = np.concatenate([onehot_features, numeric])
selected_mask = selector.get_support()
selected_features = all_feature_names[selected_mask]

# Criar DataFrame com scores
scores = selector.scores_[selected_mask]
feature_scores = pd.DataFrame({'Feature': selected_features, 'Score': scores}).sort_values(by='Score', ascending=False)



# Plotar os scores das 20 melhores features
plt.figure(figsize=(10, 6))
sns.barplot(data=feature_scores, y='Feature', x='Score', palette='viridis')
plt.title('Top 20 Features Selecionadas pelo SelectKBest (PadronizaÃ§Ã£o)')
plt.xlabel('Score F (correlaÃ§Ã£o com VALOR)')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

#tools.display_dataframe_to_user(name="Top 20 Features Selecionadas", dataframe=feature_scores)

"""#### NormalizaÃ§Ã£o"""

# Novo prÃ©-processador usando MinMaxScaler
preprocessador_minmax = ColumnTransformer([
    ("onehot", OneHotEncoder(handle_unknown='ignore'), features),
    ("minmax", MinMaxScaler(), numeric)
])

X_trans_minmax = preprocessador_minmax.fit_transform(X_full)

selector_minmax = SelectKBest(score_func=f_regression, k=20)
X_selected_minmax = selector_minmax.fit_transform(X_trans_minmax, y_full)

onehot_features_minmax = preprocessador_minmax.named_transformers_['onehot'].get_feature_names_out(features)
all_feature_names_minmax = np.concatenate([onehot_features_minmax, numeric])
selected_mask_minmax = selector_minmax.get_support()
selected_features_minmax = all_feature_names_minmax[selected_mask_minmax]

# Criar DataFrame com os scores Min-Max
scores_minmax = selector_minmax.scores_[selected_mask_minmax]
feature_scores_minmax = pd.DataFrame({
    'Feature': selected_features_minmax,
    'Score': scores_minmax
}).sort_values(by='Score', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_scores_minmax, y='Feature', x='Score', palette='magma')
plt.title('Top 20 Features Selecionadas pelo SelectKBest (NormalizaÃ§Ã£o Min-Max)')
plt.xlabel('Score F (correlaÃ§Ã£o com VALOR)')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()

"""#### ConclusÃ£o

ApÃ³s comparaÃ§Ã£o entre tÃ©cnicas de PadronizaÃ§Ã£o (StandardScaler) e NormalizaÃ§Ã£o (Min-MaxScaler), ambas apresentaram resultados muito semelhantes em relaÃ§Ã£o Ã s features selecionadas.

Para o cenÃ¡rio atual (regressÃ£o linear e Random Forest), recomenda-se continuar utilizando a tÃ©cnica de PadronizaÃ§Ã£o devido Ã s caracterÃ­sticas e desempenho dos modelos utilizados.

###10. PCA - ReduÃ§Ã£o de Dimensionalidade
"""

# PCA para 2 componentes principais
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_selected)

plt.figure(figsize=(8, 6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_full, cmap='viridis', alpha=0.5)
plt.title('VisualizaÃ§Ã£o dos Dados com PCA (2 componentes)')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.colorbar(label='Valor da Venda')
plt.show()

"""**O que estÃ¡ sendo feito:**

1.   PCA(n_components=2): Reduz a dimensionalidade do dataset (com dezenas ou centenas de variÃ¡veis apÃ³s codificaÃ§Ã£o One-Hot) para apenas 2 componentes principais.
2.   fit_transform(): Ajusta o PCA nos dados e transforma a matriz original para o novo espaÃ§o de 2 dimensÃµes.
3.   scatter(): Cria um grÃ¡fico de dispersÃ£o em 2D usando as duas componentes principais, colorindo os pontos com base na variÃ¡vel-alvo VALOR


**Por que usar PCA?**

*   Para visualizar dados de alta dimensÃ£o em um espaÃ§o compreensÃ­vel (2D).
*   Para verificar se hÃ¡ padrÃµes, agrupamentos ou separaÃ§Ãµes visÃ­veis entre exemplos.
*   Para avaliar se os dados podem ser separÃ¡veis por valor de venda ou outros comportamentos.


---

**InterpretaÃ§Ã£o do grÃ¡fico:**


1.   Eixos:

  *   Componente Principal 1 e Componente Principal 2 representam as duas direÃ§Ãµes com maior variabilidade dos dados.

2.   DistribuiÃ§Ã£o dos pontos:
  *   Os dados parecem formar agrupamentos diagonais e sequenciais.
  *   Isso pode refletir estruturas internas complexas como grupos por canal, produto, ou regiÃµes.

3.  Cor dos pontos (c=y_full):

  *   Os pontos sÃ£o coloridos conforme o valor da venda (VALOR).
  *   Tons mais claros (amarelos) indicam vendas com valor mais alto.
  *   Ã‰ visÃ­vel que valores mais altos se concentram em faixas especÃ­ficas das componentes, mostrando algum grau de separabilidade.





Isso valida o uso do PCA como ferramenta de exploraÃ§Ã£o visual e reforÃ§a que os dados sÃ£o adequados para modelos supervisionados.

#### ConclusÃ£o

A visualizaÃ§Ã£o via PCA revelou agrupamentos interessantes que sugerem subestruturas importantes nos dados:

* Os pontos formam clusters diagonais, indicando provÃ¡vel separaÃ§Ã£o natural dos dados por algumas caracterÃ­sticas dominantes, possivelmente relacionadas ao canal de distribuiÃ§Ã£o (hospitalar versus farmÃ¡cia) ou por tipos especÃ­ficos de produto ou marca;

* Os pontos mais claros (amarelos), que indicam valores mais elevados das vendas, concentram-se em Ã¡reas especÃ­ficas do grÃ¡fico, reforÃ§ando que existem padrÃµes definidos nos dados com relaÃ§Ã£o ao valor monetÃ¡rio das vendas;

* Essa segmentaÃ§Ã£o clara pode ser explorada ainda mais detalhadamente para estratÃ©gias comerciais diferenciadas ou decisÃµes logÃ­sticas.

### 11. Modelos com Dados Aprimorados

####  Modelo de estimativa do valor da venda
"""

modelos = {
    'RegressÃ£o Linear': LinearRegression(),
    'Random Forest': RandomForestRegressor(random_state=42)
}

# Pipeline completo com prÃ©-processamento e modelo preditivo
for nome, modelo in modelos.items():
    pipeline = Pipeline([
        ("preprocessador", preprocessador),
        ("seletor", SelectKBest(score_func=f_regression, k=20)),
        ("regressor", modelo)
    ])
    # AvaliaÃ§Ã£o do modelo com cross-validation
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    scores = cross_val_score(pipeline, X_full, y_full, cv=kf, scoring='r2')

    # Exibir resultados
    print(f"\nModelo: {nome} (com seleÃ§Ã£o de features)")
    print("Scores de RÂ²:", scores)
    print("MÃ©dia dos scores:", scores.mean())

"""**ANÃLISE**

Random Forest teve desempenho extremamente superior, capturando quase toda a variabilidade dos dados (RÂ² â‰ˆ 1.00) com baixÃ­ssimo erro.

A RegressÃ£o Linear ainda explica mais de 50% da variÃ¢ncia, mas seus erros mÃ©dios sÃ£o muito maiores.

Isso indica que o comportamento dos dados Ã© nÃ£o linear e que o Random Forest se adapta muito melhor Ã  complexidade do problema.

---

**AvaliaÃ§Ã£o cruzada e explicaÃ§Ã£o do alto desempenho do modelo Random Forest**

O modelo Random Forest apresentou um desempenho excepcional, com um RÂ² prÃ³ximo a 1,00. Esse resultado ocorre devido a alguns fatores importantes:

* Alta granularidade e correlaÃ§Ã£o dos atributos selecionados com o valor monetÃ¡rio das vendas.

* Capacidade intrÃ­nseca da Random Forest de capturar relaÃ§Ãµes nÃ£o lineares complexas presentes nesse dataset.

* PorÃ©m, o alto RÂ² tambÃ©m pode indicar potencial overfitting ao dataset especÃ­fico. Nesse sentido, sugere-se uma validaÃ§Ã£o adicional com outros conjuntos de dados semelhantes ou um conjunto externo separado especialmente para teste.

#### Modelo de previsÃ£o para os prÃ³ximos 6 meses
"""

# Instalar o Prophet (caso ainda nÃ£o tenha)
!pip install prophet -q

# ----- 1. Agrupamento mensal de VALOR e UNIDADES -----
df_mensal = df_limpo.groupby(['ANO', 'MES'])[['VALOR', 'UNIDADES']].sum().reset_index()
df_mensal['DATA'] = pd.to_datetime(df_mensal['ANO'].astype(str) + '-' + df_mensal['MES'].astype(str).str.zfill(2) + '-01')
df_mensal = df_mensal.sort_values('DATA').set_index('DATA')

# ----- 2. FunÃ§Ã£o geral para treino, teste e previsÃ£o futura -----
def prever_e_avaliar(df_mensal, col, nome_variavel, meses_teste=6, meses_futuro=6):
    serie = df_mensal[[col]].copy()
    serie.reset_index(inplace=True)
    serie.columns = ['ds', 'y']

    # Separar treino e teste
    df_treino = serie.iloc[:-meses_teste]
    df_teste = serie.iloc[-meses_teste:]

    # Treinar modelo
    modelo = Prophet(yearly_seasonality=True, changepoint_prior_scale=0.1)
    modelo.fit(df_treino)

    # PrevisÃ£o no mesmo perÃ­odo do teste
    futuro_teste = modelo.make_future_dataframe(periods=meses_teste, freq='MS')
    previsao_teste = modelo.predict(futuro_teste)

    # AvaliaÃ§Ã£o
    previsao_avaliacao = previsao_teste[['ds', 'yhat']].set_index('ds').join(df_teste.set_index('ds'))
    previsao_avaliacao.dropna(inplace=True)

    previsao_avaliacao = previsao_avaliacao[['y', 'yhat']].dropna()

    mae = mean_absolute_error(previsao_avaliacao['y'], previsao_avaliacao['yhat'])
    rmse = np.sqrt(mean_squared_error(previsao_avaliacao['y'], previsao_avaliacao['yhat']))


    print(f"\nðŸ“Š AvaliaÃ§Ã£o do modelo para: {nome_variavel}")
    print(f"MAE: {mae:.2f}")
    print(f"RMSE: {rmse:.2f}")

    # VisualizaÃ§Ã£o do ajuste no teste
    previsao_avaliacao[['yhat', 'y']].plot(figsize=(10, 4), title=f'Ajuste do Modelo (Teste - {nome_variavel})', ylabel=nome_variavel)
    plt.legend(['Previsto', 'Real'])
    plt.show()

    # PrevisÃ£o futura (apÃ³s todo o histÃ³rico)
    modelo_full = Prophet()
    modelo_full.fit(serie)

    futuro_futuro = modelo_full.make_future_dataframe(periods=meses_futuro, freq='MS')
    previsao_futura = modelo_full.predict(futuro_futuro).set_index('ds')[[ 'yhat' ]].iloc[-meses_futuro:]
    previsao_futura.columns = [f'{nome_variavel}_PREVISTO']

    return previsao_futura

# ----- 3. Executar previsÃ£o com avaliaÃ§Ã£o -----
previsao_valor = prever_e_avaliar(df_mensal, 'VALOR', 'VALOR')
previsao_unidades = prever_e_avaliar(df_mensal, 'UNIDADES', 'UNIDADES')

# ----- 4. Combinar previsÃµes futuras -----
previsoes_finais = previsao_valor.join(previsao_unidades)
previsoes_finais.reset_index(inplace=True)
previsoes_finais.rename(columns={'ds': 'MES'}, inplace=True)

"""### 12. ConclusÃ£o e RecomendaÃ§Ãµes



"""

fig, axs = plt.subplots(2, 2, figsize=(16, 10))

# 1. Qual canal de venda apresenta maior valor mÃ©dio?
sns.boxplot(data=df_limpo, x='CANAL', y='VALOR', ax=axs[0, 0])
axs[0, 0].set_title('Valor de Venda por Canal')
axs[0, 0].set_xlabel('Canal')
axs[0, 0].set_ylabel('Valor (R$)')

# 2. Valor unitÃ¡rio mÃ©dio por regiÃ£o
sns.boxplot(data=df_limpo, x='REGIAO', y='VALOR_UNITARIO', ax=axs[0, 1])
axs[0, 1].set_title('Valor UnitÃ¡rio por RegiÃ£o')
axs[0, 1].set_xlabel('RegiÃ£o')
axs[0, 1].set_ylabel('Valor UnitÃ¡rio (R$)')
axs[0, 1].tick_params(axis='x', rotation=45)

# 3. Comparativo do valor mÃ©dio por ano
sns.boxplot(data=df_limpo, x='ANO', y='VALOR', ax=axs[1, 0])
axs[1, 0].set_title('Valor de Venda por Ano')
axs[1, 0].set_xlabel('Ano')
axs[1, 0].set_ylabel('Valor (R$)')

# 4. Valor de venda por marca
top_marcas = df_limpo['MARCA'].value_counts().index[:5]  # limitar Ã s 5 maiores
sns.boxplot(data=df_limpo[df_limpo['MARCA'].isin(top_marcas)], x='MARCA', y='VALOR', ax=axs[1, 1])
axs[1, 1].set_title('Valor de Venda por Marca (Top 5)')
axs[1, 1].set_xlabel('Marca')
axs[1, 1].set_ylabel('Valor (R$)')

plt.tight_layout()
plt.show()

"""1. Qual canal de venda apresenta maior valor mÃ©dio?

*   Hospitalar e Outros possuem valores mÃ©dios similares, significativamente maiores que o canal FarmÃ¡cia;
*   O canal FarmÃ¡cia apresenta menor dispersÃ£o e menor valor mÃ©dio, indicando vendas menores e possivelmente mais frequentes;
*   O canal Hospitalar mostra maior variabilidade, com valores altos frequentes, sugerindo tratamentos de alto custo concentrados nesse canal.


2. Valor unitÃ¡rio mÃ©dio por regiÃ£o

*   As regiÃµes apresentam valores unitÃ¡rios mÃ©dios bastante prÃ³ximos, sem grandes diferenÃ§as evidentes;
*   A regiÃ£o Nordeste mostra uma leve tendÃªncia a ter valores unitÃ¡rios medianos mais elevados;
*   A dispersÃ£o relativamente uniforme em todas as regiÃµes sugere consistÃªncia nacional na precificaÃ§Ã£o por unidade, sem diferenÃ§as regionais muito marcantes.

3. Comparativo do valor mÃ©dio por ano

*   Os valores mÃ©dios anuais se mantÃªm relativamente estÃ¡veis entre 2023 e 2025, sem grandes variaÃ§Ãµes:
*   A presenÃ§a constante de valores elevados (outliers) ao longo dos anos indica que tratamentos caros persistem regularmente ao longo do tempo:
*   NÃ£o hÃ¡ uma tendÃªncia clara de aumento ou diminuiÃ§Ã£o significativa no valor mÃ©dio, sugerindo estabilidade no mercado durante esses anos.

4. Valor de venda por marca (Top 5)

*   Marca F claramente se destaca com um valor mÃ©dio mais alto e maior dispersÃ£o, indicando que seus produtos tendem a ser vendidos por preÃ§os mais elevados e variados;
*   As marcas A, B, D e H possuem valores mÃ©dios relativamente prÃ³ximos, sendo a marca A com os menores valores mÃ©dios dentre as cinco principais;
*   A alta quantidade de valores discrepantes (outliers) em todas as marcas indica que hÃ¡ uma diversidade considerÃ¡vel de preÃ§os praticados mesmo dentro das principais marcas.






"""

# ----- 5. Visualizar previsÃµes futuras -----
display(previsoes_finais)

fig_valor = px.bar(previsoes_finais, x='MES', y='VALOR_PREVISTO', title='ðŸ“ˆ PrevisÃ£o de Valor Total das Vendas (R$)', text_auto='.2s')
fig_unidades = px.bar(previsoes_finais, x='MES', y='UNIDADES_PREVISTO', title='ðŸ“¦ PrevisÃ£o de Unidades Vendidas', text_auto='.2s')

fig_valor.show()
fig_unidades.show()

"""5. Como serÃ¡ a evoluÃ§Ã£o do valor total das vendas nos prÃ³ximos meses?


*   HÃ¡ uma tendÃªncia clara de crescimento gradual no valor total das vendas previsto, subindo de aproximadamente R$ 65,9 milhÃµes em Fevereiro para cerca de R$ 69,1 milhÃµes em Julho de 2025;
*   Essa evoluÃ§Ã£o crescente indica que o mercado para medicamentos de cÃ¢ncer de prÃ³stata pode estar em expansÃ£o, sugerindo aumento de consumo ou aumento do valor mÃ©dio dos medicamentos vendidos.

6. Qual Ã© a previsÃ£o para as unidades vendidas?

*   O nÃºmero de unidades vendidas tambÃ©m mostra tendÃªncia positiva, com previsÃ£o de aumento mensal contÃ­nuo, iniciando em cerca de 6.457 unidades em Fevereiro e alcanÃ§ando aproximadamente 6.684 unidades em Julho;
*   O crescimento consistente das unidades vendidas reforÃ§a a interpretaÃ§Ã£o de aumento na demanda pelos medicamentos analisados.

7. Quais insights estratÃ©gicos podem ser obtidos a partir dessas previsÃµes?


*   A previsÃ£o demonstra um mercado aquecido e em expansÃ£o moderada, sugerindo oportunidades para investimento em logÃ­stica, estoques, negociaÃ§Ãµes com fornecedores e expansÃ£o em canais estratÃ©gicos (especialmente hospitalares);
*   Com o aumento previsto nas unidades, Ã© importante assegurar disponibilidade e evitar rupturas nos estoques dos principais canais.

---
**ConclusÃ£o e recomendaÃ§Ã£o**

* A previsÃ£o sugere estabilidade positiva no mercado, com crescimento gradativo tanto em faturamento quanto em volume;

* Recomenda-se monitorar continuamente esses valores previstos e ajustÃ¡-los com novas variÃ¡veis externas, como campanhas de saÃºde pÃºblica ou mudanÃ§as regulatÃ³rias que possam influenciar diretamente a demanda futura.




"""